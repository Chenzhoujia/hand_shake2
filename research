数据构造
    train,train.py
    TextLoader中将整个文档分为1352份,每份就是一个网络输入,计算一个loss.每份包含[50,50]的int64的数据,每个对应一个字符
    embedding_lookup,__init__,model.py中将,用97种数字表示的字符变成转换为有用的连续向量https://vimsky.com/article/3656.html
    最终得到1352份[50,50,128]的输入
    __init__,model.py中将输入拆分成rnn需要的模式,具体而言,按照*号中取[[*...],[*...],[*..50.]...50个...,[*...],[*...]],得到[50,128]作为网络的一个batch

网络计算
    rnn_decoder,seq2seq.py,model.py,train.py中实现了具体操作,其中网络结构是在之前的self.cell中定义的.包括网络输入输出维度,网络层数
    网络输入一个字符编码(128),经过两个中间层后,输出一个字符编码(128)并保存:output, state = cell(inp, state);outputs.append(output)

    最终的输出是用一个128*97的矩阵将128编码映射回97字符编码得到(2500,97)

loss计算
    sparse_softmax_cross_entropy_with_logits计算了:输出(2500,97)目标(2500)之间的误差
    网络可供训练的参数有三个部分:<1>cell*2 (256,512)(512)<2>embedding<3>网络输出

    [不知道大小为什么是这样而不是(128,128),会不会跟dropout有关?,或者是LSTm本身的各种门决定的]

玩弄一下这个网络:

(1)参数加载,测试输出,看看github工程
(2)网络参数确认,网络参数调整
(3)工程转换设计


分析为什么比wave慢,特征提取效果不够好







